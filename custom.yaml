DEVICE          : cpu              # device used for training and evaluation (cpu, cuda, cuda0, cuda1, ...)
SAVE_DIR        : 'segformer_unn/assets/output'         # output folder name used for saving the model, logs and inference results

MODEL:                                    
  NAME          : HarDNet                                           # name of the model you are using
  VARIANT       : '70'                                                  # model variant
  PRETRAINED    : 'checkpoints/backbones/hardnet/hardnet_70.pth'              # backbone model's weight 

DATASET:
  NAME          : cityscapes                                              # dataset name to be trained with (camvid, cityscapes, ade20k)
  ROOT          : 'segformer_unn/assets/input'                         # dataset root path

TRAIN:
  IMAGE_SIZE    : [1024, 1024]    # training image size in (h, w)
  BATCH_SIZE    : 8               # batch size used to train
  EPOCHS        : 500             # number of epochs to train
  EVAL_INTERVAL : 50              # evaluation interval during training
  AMP           : false           # use AMP in training
  DDP           : false           # use DDP training

LOSS:
  NAME          : ohemce          # loss function name (ohemce, ce, dice)
  CLS_WEIGHTS   : true            # use class weights in loss calculation
  THRESH        : 0.9             # ohemce threshold or dice delta if you choose ohemce loss or dice loss

OPTIMIZER:
  NAME          : adamw           # optimizer name
  LR            : 0.01            # initial learning rate used in optimizer
  WEIGHT_DECAY  : 0.0001          # decay rate used in optimizer 

SCHEDULER:
  NAME          : warmuppolylr    # scheduler name
  POWER         : 0.9             # scheduler power
  WARMUP        : 10              # warmup epochs used in scheduler
  WARMUP_RATIO  : 0.1             # warmup ratio
  

EVAL:
  MODEL_PATH    : 'hardnet70_cityscapes.pth'  # trained model file path
  IMAGE_SIZE    : [1024, 2048]                                                            # evaluation image size in (h, w)                       
  MSF: 
    ENABLE      : false                                                                 # multi-scale and flip evaluation  
    FLIP        : true                                                                  # use flip in evaluation  
    SCALES      : [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]                                     # scales used in MSF evaluation                


TEST:
  MODEL_PATH    : 'hardnet70_cityscapes.pth'  # trained model file path
  FILE          : 'segformer_unn/assets/input'                                                   # filename or foldername 
  IMAGE_SIZE    : [1024, 2048]                                                           # inference image size in (h, w)
  OVERLAY       : false                                                                  # save the overlay result (image_alpha+label_alpha)
